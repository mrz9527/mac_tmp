# 常见概念

* 容器(Container)
  容器就是一种文件格式，比如flv、mkv、mp4等。包含下面5种流以及文件头信息。

* 流(Stream)
  是一种视频数据信息的传输方式，5种流：音频，视频，字幕，附件，数据。
* 包(Packet)
  在ffmpeg中包代表已经编码好的一个单位的音频或者视频。

* 帧(Frame)
  在ffmpeg中帧代表一幅静止的图像（yuv数据）或一些数量的音频采样。

* 编解码器(Codec)

  是对视频进行压缩或者解压缩，CODEC =ENCode （编码） +DECode（解码）

* 复用/解复用(mux/demux)
  把不同的流按照某种容器的规则放入容器，这种行为叫做复用（mux）
  把不同的流从某种容器中解析出来，这种行为叫做解复用(demux)



# 视频格式转化

 	以h264+aac编码的flv文件转码为 h265+mp3编码的mp4文件为例。

![image-20210825223238416](/Users/xm210408/Library/Application Support/typora-user-images/image-20210825223238416.png)



# 视频播放流程

 ```
 容器：音视频封装后的视频文件（flv、mkv、mp4等），主要存放压缩的音频和视频
 
 容器解封为：
 	压缩的音频（aac、mp3等）
 			音频解码
 				得到音频采样数据 pcm（通用数据格式，可以直接在声卡上放）
 	压缩的视频（h264、h265等）
 			视频解码
 				得到视频像素数据 yuv（不是rgb数据格式）
 ```

  视频文件（容器）要播放，拆开（解封）为独立的音频（aac、mp3等）和视频（h264、h265等），此时的音频和视频还处于压缩状态；音频解码得到pcm（pcm是原始的音频采样数据），视频解码得到yuv或者rgb，一般用yuv（yuv或rgb是原始的视频采样数据，一帧一帧的图像），pcm放到声卡播放，yuv放到显卡播放。



## FFmpeg模块

libavformat：用于各种音视频封装格式的生成和解析，包括获取解码所需信息以生成解码上下文结构和读取音视频帧等功能；
 libavcodec：用于各种类型声音/图像编解码；
 libavutil：包含一些公共的工具函数；
 libswscale：用于视频场景比例缩放、色彩映射转换；
 libpostproc：用于后期效果处理；
 ffmpeg：该项目提供的一个工具，可用于格式转换、解码或电视卡即时编码等；
 ffsever：一个 HTTP 多媒体即时广播串流服务器；
 ffplay：是一个简单的播放器，使用ffmpeg 库解析和解码，通过SDL显示；

## 

# 视频解码后的数据格式



  ```
  视频：yuv
  
  音频：pcm
  ```



# mp4等视频信息

 ```
  Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'SampleVideo_1280x720_2mb.mp4':
    Metadata:
      major_brand     : isom
      minor_version   : 512
      compatible_brands: isomiso2avc1mp41
      creation_time   : 1970-01-01T00:00:00.000000Z
      encoder         : Lavf53.24.2
    Duration: 00:00:13.50, start: 0.000000, bitrate: 1248 kb/s
    Stream #0:0(und): Video: h264 (Main) (avc1 / 0x31637661), yuv420p, 1280x720 [SAR 1:1 DAR 16:9], 862 kb/s, 25 fps, 25 tbr, 12800 tbn (default)
      Metadata:
        creation_time   : 1970-01-01T00:00:00.000000Z
        handler_name    : VideoHandler
        vendor_id       : [0][0][0][0]
    Stream #0:1(und): Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, 5.1, fltp, 381 kb/s (default)
      Metadata:
        creation_time   : 1970-01-01T00:00:00.000000Z
        handler_name    : SoundHandler
        vendor_id       : [0][0][0][0]
 ```



# mp4提取和播放yuv和pcm数据

 ```
 提取yuv数据
 ffmpeg -i SampleVideo_1280x720_2mb.mp4 -an -c:v rawvideo -pixel_format yuv420p out.yuv
 
 播放yuv视频（此时没有声音）
 ffplay -s 1280x720 out.yuv
 
 
 提取pcm数据
 ffmpeg -i SampleVideo_1280x720_2mb.mp4 -vn -ar 48000 -ac 2 -f s16le out.pcm
 (提取出pcm时设置的ac音频通道数是2，原始的应该是5，为什么为这里设置为2（设置为1也是可以的）？是因为我们的电脑是双声道的，设置为5，电脑放不出来效果，还会导致音质混乱)
 
 
 播放pcm音频（此时没有画面）
  ffplay -ar 44800 -ac 2 -f s16le -i out.pcm
 ```



# 视频码率计算

	原始mp4视频码率：
		(yuv420p, 一个像素，y占一个字节，8bit，一个像素u平均是8/4=2bit,v平均是8、4=2bit，所以yuv总共是1.5*8=12bit)	
		手动计算视频码率 = 帧率 * 像素（图像尺寸） * 每个像素采用的bit数 = 25 * (1280 * 720) * (1.5 * 8) bit/s= 276480000 bit/s = 276480 kb/s 
		实际输出视频码率 = 862kb/s（这个值来自于mp4文件）
		手动计算视频码率 != 实际输出视频码率
		
	如果采用提取yuv420格式后的yuv文件来计算码率：确实为276480 kb/s（这个值来自于yuv文件）



# api介绍

## av_dump_format

​	打印关于输入或输出格式的详细信息，例如持续时间，比特率，流，容器，程序，元数据，边数据，编解码器和时基。

 ```c
 /**
  * Print detailed information about the input or output format, such as
  * duration, bitrate, streams, container, programs, metadata, side data,
  * codec and time base.
  *
  * @param ic        the context to analyze
  * @param index     index of the stream to dump information about
  * @param url       the URL to print, such as source or destination file
  * @param is_output Select whether the specified context is an input(0) or output(1)
  */
 void av_dump_format(AVFormatContext *ic,
                     int index,
                     const char *url,
                     int is_output);
 ```

代码示例

```c
#include <iostream>
 
extern "C"
{
#include "libavformat/avformat.h"
}
 
using namespace std;
 
#pragma comment(lib,"avformat.lib")
#pragma comment(lib,"avutil.lib")
 
int ff_Error(int errNum)
{
	char buf[1024] = { 0 };
	av_strerror(errNum, buf, sizeof(buf));
	cout << buf << endl;
	system("pause");
	return -1;
}
 
int main()
{
	char *inUrl = "D:\\TestFiles\\test.flv";
	av_register_all();
 
	AVFormatContext *ictx = NULL;
 
	//打开文件，解封文件头
	int re = avformat_open_input(&ictx, inUrl, 0, 0);
	if (re != 0)
	{
		return ff_Error(re);
	}
 
	cout << "open file " << inUrl << " success..." << endl;
 
	//获取音频视频流信息 ,h264 flv
	re = avformat_find_stream_info(ictx, 0);
	if (re != 0)
	{
		return ff_Error(re);
	}
 
	//打印流信息
	//注意：最后一个参数填0，打印输入流；最后一个参数填1，打印输出流
	av_dump_format(ictx, 0, inUrl, 0);  
 
	system("pause");
	return 0;
}
```



![img](https://img-blog.csdnimg.cn/20200128203806312.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9taW5nc2hpcWlhbmcuYmxvZy5jc2RuLm5ldA==,size_16,color_FFFFFF,t_70)





## FFmpeg优化

1 内存优化。内存往上涨。没能及时回收。最好能够使用手动管理内存。
 解码优化，看ffmpeg文档，最新的解码库，解码效率，稳定性，综合性考虑。
 YUV->RGB  OpenGLES shader来显示。

## FFmpeg转码

1.分离视频音频流
 ffmpeg -i input_file -vcodec copy -an output_file_video　　//分离视频流
 ffmpeg -i input_file -acodec copy -vn output_file_audio　　//分离音频流
 2.视频解复用
 ffmpeg –i test.mp4 –vcodec copy –an –f m4v test.264
 ffmpeg –i test.avi –vcodec copy –an –f m4v test.264
 3.视频转码
 ffmpeg –i test.mp4 –vcodec h264 –s 352*278 –an –f m4v test.264              //转码为码流原始文件
 ffmpeg –i test.mp4 –vcodec h264 –bf 0 –g 25 –s 352*278 –an –f m4v test.264  //转码为码流原始文件
 ffmpeg –i test.avi -vcodec mpeg4 –vtag xvid –qsame test_xvid.avi            //转码为封装文件
 //-bf B帧数目控制，-g 关键帧间隔控制，-s 分辨率控制
 4.视频封装
 ffmpeg –i video_file –i audio_file –vcodec copy –acodec copy output_file
 5.视频剪切
 ffmpeg –i test.avi –r 1 –f image2 image-%3d.jpeg        //提取图片
 ffmpeg -ss 0:1:30 -t 0:0:20 -i input.avi -vcodec copy -acodec copy output.avi    //剪切视频
 //-r 提取图像的频率，-ss 开始时间，-t 持续时间
 6.视频录制
 ffmpeg –i [rtsp://192.168.3.205:5555/test](https://links.jianshu.com/go?to=rtsp%3A%2F%2F192.168.3.205%3A5555%2Ftest) –vcodec copy out.avi
 7.YUV序列播放
 ffplay -f rawvideo -video_size 1920x1080 input.yuv
 8.YUV序列转AVI
 ffmpeg –s w*h –pix_fmt yuv420p –i input.yuv –vcodec mpeg4 output.avi
